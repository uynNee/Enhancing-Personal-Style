{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴인식 테스트 (Haar Cascade)\n",
    "    \n",
    "    최초 작성일 : 20/02/14\n",
    "    작성자 : 양희승\n",
    "    \n",
    "    작성내용 : 얼굴인식 테스트, 눈인식 테스트, 크롭 테스트\n",
    "    \n",
    "    수정내용 :\n",
    "        20/02/15 \n",
    "            - 옆모습 인식 테스트, 볼 부분 인식 위치 변경\n",
    "            \n",
    "            \n",
    "        20/02/18\n",
    "            - 볼의 색상 추출 과정 정리\n",
    "            - 각 단계 이미지 저장\n",
    "            - 코드 한 쉘로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본이미지 로드\n",
    "origin_img = cv.imread(\"img/sorter_test2.jpg\")\n",
    "# cv.imshow(\"temple\", origin_img)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv의 얼굴인식 이용\n",
    "faceCascade = cv.CascadeClassifier('data/haarcascade_frontface.xml') \n",
    "\n",
    "gray = cv.cvtColor(origin_img, cv.COLOR_BGR2GRAY) \n",
    "# faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "faces = faceCascade.detectMultiScale(gray, 1.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Count : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Face Count : {0}\".format(len(faces))) \n",
    "\n",
    "for (x, y, w, h) in faces: \n",
    "    cv.rectangle(origin_img, (x, y), (x+w, y+h), (0, 255, 0), 2) \n",
    "\n",
    "cv.imshow(\"Face\", origin_img) \n",
    "cv.imwrite(\"img/222.jpg\", origin_img)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() \n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#눈 인식 테스트\n",
    "faceCascade_eye = cv.CascadeClassifier('data/haarcascade_eye.xml') \n",
    "\n",
    "gray = cv.cvtColor(origin_img, cv.COLOR_BGR2GRAY) \n",
    "faces = faceCascade_eye.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30) ) \n",
    "\n",
    "for (x, y, w, h) in faces: \n",
    "    cv.rectangle(origin_img, (x, y), (x+w, y+h+10), (0, 255, 0), 2) \n",
    "\n",
    "cv.imshow(\"Face\", origin_img) \n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() \n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 인식 후 잘라서 저장\n",
    "for (x, y, w, h) in faces: \n",
    "    # 얼굴 인식부분에 사각형 씌우기\n",
    "    cv.rectangle(origin_img, (x, y), (x+w, y+h), (255, 0, 0), 2) \n",
    "    #원본이미지, 시작지점, 종료지점, 색깔, 선두께 \n",
    "\n",
    "#     cropped = origin_img[y - int(h/4):y + h + int(h/4), x - int(w/4):x + w + int(w/4)]\n",
    "    cropped = origin_img[y:y + h, x:x + w]\n",
    "    cv.imwrite(\"img/cropped_1.png\", cropped)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = origin_img[y:y+h, x:x+w]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옆모습이라면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옆모습 사진 로드\n",
    "side_img = cv.imread(\"img/02.jpg\")\n",
    "# cv.imshow(\"temple\", side_img)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv의 얼굴인식 이용\n",
    "faceCascade = cv.CascadeClassifier('data/haarcascade_frontface.xml') \n",
    "\n",
    "gray = cv.cvtColor(side_img, cv.COLOR_BGR2GRAY) \n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Count : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Face Count : {0}\".format(len(faces))) \n",
    "\n",
    "for (x, y, w, h) in faces: \n",
    "    cv.rectangle(side_img, (x, y), (x+w, y+h), (0, 255, 0), 2) \n",
    "\n",
    "cv.imshow(\"Face\", side_img) \n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() \n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옆모습은 어차피 찾지도 못한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 볼 부분으로 인식하게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Count : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Face Count : {0}\".format(len(faces))) \n",
    "\n",
    "for (x, y, w, h) in faces: \n",
    "    cv.rectangle(origin_img, (x, y), (x+w, y+h), (0, 255, 0), 2) \n",
    "\n",
    "cv.imshow(\"Face\", origin_img) \n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() \n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 195 56 56\n",
      "159 207 61 61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#눈 인식 테스트\n",
    "# 원본이미지 로드\n",
    "origin_img = cv.imread(\"img/01.jpg\")\n",
    "\n",
    "faceCascade_eye = cv.CascadeClassifier('data/haarcascade_eye.xml') \n",
    "\n",
    "gray = cv.cvtColor(origin_img, cv.COLOR_BGR2GRAY) \n",
    "eyes = faceCascade_eye.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30) ) \n",
    "\n",
    "for (x, y, w, h) in eyes: \n",
    "    print(x,y,w,h)\n",
    "#     cv.rectangle(origin_img, (x, y+30), (x+30, y+30+15), (0, 255, 0), 2) \n",
    "    cv.rectangle(origin_img, (x, y+45), (x+w-10, y+45+h), (0, 255, 0), 2) \n",
    "\n",
    "cv.imshow(\"Face\", origin_img) \n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() \n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러명 인식 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한 사람만 찍힌 사진을 올려주세요\n"
     ]
    }
   ],
   "source": [
    "# 여러명 이미지 로드\n",
    "origin_img = cv.imread(\"img/other2.jpg\")\n",
    "faceCascade = cv.CascadeClassifier('data/haarcascade_frontface.xml') \n",
    "\n",
    "gray = cv.cvtColor(origin_img, cv.COLOR_BGR2GRAY) \n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30) ) \n",
    "\n",
    "if len(faces) > 1 :\n",
    "    print(\"한 사람만 찍힌 사진을 올려주세요\")\n",
    "elif len(faces) == 1 :\n",
    "    for (x, y, w, h) in faces: \n",
    "        cv.rectangle(origin_img, (x, y), (x+w, y+h), (0, 255, 0), 2) \n",
    "\n",
    "    cv.imshow(\"Face\", origin_img) \n",
    "    cv.waitKey(0) \n",
    "    cv.destroyAllWindows() \n",
    "    cv.waitKey(1)\n",
    "elif len(faces) == 0 :\n",
    "    print(\"정면이거나 정상적인 사진을 올려주세요\")\n",
    "else :\n",
    "    print(\"에러\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 볼이미지 자르고 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 308 267 267\n",
      "663 311 257 257\n",
      "992 770 66 66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"test1\"\n",
    "origin_img = cv.imread(\"img/\"+file_name+\".jpg\")\n",
    "\n",
    "\n",
    "# opencv의 얼굴인식 이용, 눈 인식 이용\n",
    "faceCascade = cv.CascadeClassifier('data/haarcascade_frontface.xml') \n",
    "faceCascade_eye = cv.CascadeClassifier('data/haarcascade_eye.xml') \n",
    "\n",
    "\n",
    "# Gray 컬러 변환\n",
    "gray = cv.cvtColor(origin_img, cv.COLOR_BGR2GRAY) \n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30) ) \n",
    "\n",
    "\n",
    "face_cropped = None\n",
    "cheek_cropped = None\n",
    "\n",
    "\n",
    "# face_detection\n",
    "if len(faces) > 1 :\n",
    "    print(\"한 사람만 찍힌 사진을 올려주세요\")\n",
    "elif len(faces) == 1 :\n",
    "    for (x, y, w, h) in faces: \n",
    "        cv.rectangle(origin_img, (x, y), (x+w, y+h), (255, 0, 0), 2) \n",
    "    #     cv.imshow(\"Face\", origin_img) \n",
    "        cv.imwrite(\"img/\"+file_name+\"1.jpg\", origin_img)\n",
    "        face_cropped = origin_img[y:y + h, x:x + w]\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = origin_img[y:y+h, x:x+w]\n",
    "elif len(faces) == 0 :\n",
    "    print(\"정면이거나 정상적인 사진을 올려주세요\")\n",
    "else :\n",
    "    print(\"에러\")\n",
    "        \n",
    "face_cropped\n",
    "# cv.imshow(\"Face\", face_cropped) \n",
    "cv.imwrite(\"img/\"+file_name+\"2.jpg\", face_cropped)\n",
    "gray = cv.cvtColor(face_cropped, cv.COLOR_BGR2GRAY) \n",
    "eyes = faceCascade_eye.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30) ) \n",
    "\n",
    "\n",
    "# cheek_detection\n",
    "for i in range(len(eyes)): \n",
    "    x, y, w, h = eyes[i]\n",
    "    print(x,y,w,h)\n",
    "#     cv.rectangle(origin_img, (x, y+30), (x+30, y+30+15), (0, 255, 0), 2) \n",
    "#     cv.rectangle(face_cropped, (x+80, y+h+125), (x+120, y+h+125+80), (0, 255, 0), 2)\n",
    "    cv.imshow(\"Face\", face_cropped) \n",
    "    cv.imwrite(\"img/\"+file_name+\"3.jpg\", face_cropped)\n",
    "    if i == 0 :\n",
    "        cheek_cropped1 = face_cropped[y+h+125:y+h+125+80, x+80:x+120]\n",
    "    elif i == 1 :\n",
    "        cheek_cropped2 = face_cropped[y+h+125:y+h+125+80, x+80:x+120]\n",
    "        final = np.hstack((cheek_cropped1, cheek_cropped2))\n",
    "#     print(cheek_cropped.shape)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "cv.imshow(\"Face\", final) \n",
    "cv.imwrite(\"img/\"+file_name+\"4.jpg\", final)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() \n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
